[set_internal_index]
definition = index=_internal

[set_audit_index]
definition = index=_audit

[set_sos_index]
definition = index=sos

[get_splunk_servers]
# In order to contend with the case where no instance-wide value is defined for "host" in inputs.conf, we try two methods. This all happens in the "getinternalhost.py" command.
# First, we use btool on inputs to retreive the host value from the "$SPLUNK_HOME/var/log/splunk" default input stanza. 
# If this fails, then we fall back on socket.gethostname() just as splunkd does when no host value is associated with that input stanza.

definition = getallhosts | eval sos_server=if(isnotnull(btoolHostname),btoolHostname,pythonHostname) | append [| getlocalhost | eval sos_server=if(isnotnull(btoolHostname),btoolHostname,pythonHostname) | fields sos_server _time] | fields sos_server _time | eventstats dc(sos_server) AS dc | stats count, max(dc) AS dc max(_time) AS _time by sos_server | eval server_role=case(dc=1,"stand-alone indexer",dc>1 AND count=2,"search-head",count=1,"search-peer")

[get_splunk_instances_info]
definition = serverinfo | stats first(*) AS * by sos_server | append [entity namespace=None properties/server/license] | eval title=_raw | eval master_uri=if(title=="master_uri",entityContent,"") | eval license_role=case(master_uri=="self","License master",like(master_uri,"http%"),"License slave, reporting to master_uri : \"".master_uri."\"",isnull(master_uri),"n/a") | append [entity namespace=None properties/authentication/authentication] | eval title=_raw | eval auth_method=if(title=="authType",entityContent,"") | eval auth_method=case(isnull(auth_method),"not available",auth_method=="Splunk","Splunk built-in",isnotnull(auth_method),auth_method) | search source=serverinfo OR license_role!="" OR auth_method!="" | append [entity namespace=None server/info] | append [entity namespace=None server/settings] | fields sos_server cpu_count host_fqdn total_phys_mem_gb version build os_name cpu_arch SPLUNK_HOME SPLUNK_DB license_role auth_method | fields - _time _raw | stats first(*) AS * by sos_server

# yields a single row with values like aggqueue_color, aggqueue_value, whose 
# respective values might be "color5", "62.1"
[make_colors_and_values(1)]
args = percentField
definition = eval color=case($percentField$ <10, "color1", $percentField$<20, "color2", $percentField$<30, "color3", $percentField$<40, "color4", $percentField$<50, "color5", $percentField$<60, "color6", $percentField$<70, "color7", $percentField$<80, "color8", $percentField$<90, "color9", $percentField$<=100, "color10") | eval {name}_color=color | eval {name}_value=outputField | fields - name color outputField | stats last(*) as *

[input_components]
definition = component="ArchiveProcessor" OR component="BatchReader" OR component="ExecProcessor" OR component="FileClassifier" OR component="FileClassifierManager" OR component="FileInputTracker" OR component="FilesystemChangeWatcher"OR component="FSChangeMonitor" OR component="TcpInputProcessor" OR component="TailingProcessor" OR component="UDPInputProcessor" OR component="WatchedFile" OR component="WinEventLog" OR component="WinEventLogChannel" OR component="WinEventLogInputProcessor"

[default_props_stanzas]
definition = stanza=ActiveDirectory OR stanza=backup_file OR stanza=manpage OR stanza=misc_text OR stanza=mysqld_error OR stanza=osx_crash_log OR stanza=sar OR stanza=splunk_help OR stanza=web OR stanza=weblogic_stdout OR stanza=PerformanceMonitor OR stanza=WinRegistry OR stanza="source::WinEventLog..." OR stanza=stash OR stanza=stash_new OR stanza=wmi

[default_transforms_stanzas]
definition = stanza=novell-groupwise-arrival OR stanza=novell-groupwise-queue OR stanza=novell-groupwise-transfer OR stanza=sendToTCP OR stanza=send_to_nullqueue OR stanza=set_sourcetype_to_stash OR stanza=splunk_help OR stanza=splunk_index_history OR stanza=splunkd-disassembler OR stanza=strip-winevt-linebreaker OR stanza=syslog-header-stripper-ts OR stanza=syslog-header-stripper-ts-host OR stanza=syslog-header-stripper-ts-host-proc OR stanza=syslog-host OR stanza=syslog-host-full OR stanza=wmi-host OR stanza=wmi-override-host

[get_splunk_process_type]
definition = eval type=case(like(ARGS, "%search%"),"searches",like(ARGS, "%root.py_%start%") OR like(COMMAND, "%splunkweb%") OR (like(COMMAND,"%python%") AND like(ARGS,"%appserver%")), "Splunk Web",like(ARGS,"%-p_%start%") OR (like(COMMAND,"%splunkd%") AND like(ARGS, "service")),"splunkd server")

[get_splunk_process_type_lsof]
definition = eval process=case(like(COMMAND,"%python%"),"Splunk Web",like(COMMAND,"%splunkd%"),"splunkd")

[get_search_type]
definition = eval searchType=case(like(label,"%AUTOSUMMARY%"),"auto summary",like(sid,"13%.%") OR like(sid,"14%.%"),"historical",like(sid,"rt_%"),"real-time",like(sid,"scheduler__%"),"scheduled",like(sid,"subsearch_%"),"subsearch",like(sid,"remote_%"),"remote",isint("1"),"unknown")

[cluster_components]
definition = component="Cluster*" OR component="CM*"

[anomalous_log_level]
definition = log_level=WARN OR log_level=ERROR OR log_level=CRIT OR log_level=FATAL

[get_rank_rack(1)]
args = server_role
#definition = eval sort_rank=case(like($server_role$,"%search%head%"),1,like($server_role$,"%indexer%") OR like($server_role$,"%peer%"),2,like($server_role$,"%forwarder%"),3) | eval rack=case(sort_rank=1,"SH",sort_rank=2,"IDX",sort_rank=3,"FWD")
#The above does not take into account the stand-alone server designation. This needs clarity.
definition = eval sort_rank=99 | eval sort_rank=case(like($server_role$,"%search%head%"),1,like($server_role$,"%indexer%") OR like($server_role$,"%peer%"),2,like($server_role$,"%forwarder%"),3) | eval rack=case(sort_rank=1,"SH",sort_rank=2,"IDX",sort_rank=3,"FWD") | eval status=$server_status$
iseval = 0

[get_role_group(1)]
args = server_role
definition = eval sort_rank=99 |eval sort_rank=case(like($server_role$,"%search%head%"),1,like($server_role$,"%indexer%") OR like($server_role$,"%peer%"),2,like($server_role$,"%forwarder%"),3) | eval role_group=case(sort_rank=1,"SH",sort_rank=2,"IDX",sort_rank=3,"FWD")
iseval = 0

[curate_splunk_servers_cache]
definition = stats first(server_role) AS server_role max(_time) AS _time by sos_server | eval server_label=server_role." : ".sos_server | eval sort_rank=99 | eval sort_rank=case(like(server_role,"%search%head%"),1,like(server_role,"%indexer%") OR like(server_role,"%peer%"),2,like(server_role,"%forwarder%"),3)

[get_op_category]
definition = eval op_category = case(op_type == "write","write",op_type == "read","read",op_type == "access" OR op_type == "getattr" OR op_type = "lookup","access/getattr/lookup", isnotnull(op_type), "other")

[search_head_filter]
definition = [inputlookup splunk_servers_cache | search server_role="search-head" | eval host = sos_server | fields host]

[base_license_summary_search]
definition = `set_internal_index` source=*license_usage.log type="RolloverSummary" earliest=-30d@d

[base_license_usage_search]
definition = `set_internal_index` source=*license_usage.log type="Usage" | eval h=if(len(h)=0 OR isnull(h),"(SQUASHED)",h) | eval s=if(len(s)=0 OR isnull(s),"(SQUASHED)",s) | eval idx=if(len(idx)=0 OR isnull(idx),"(UNKNOWN)",idx) | bin _time span=1d | stats sum(b) as b by _time, pool, s, st, h, idx

[usage_panel-generate_search_string(2)]
args = splitby, pool_name
definition = eval search_string = case(\
$splitby$=="none","`base_license_summary_search` pool=$pool_name$ | dedup slave, date_mday | eval _time=_time - 43200 | bin _time span=1d | stats sum(b) AS b by _time | eval GB = round(b/1024/1024/1024,3) | timechart span=1d max(GB) AS volume fixedrange=false",\
\
$splitby$=="pool","`base_license_summary_search` pool=$pool_name$ | dedup slave, date_mday | eval _time=_time - 43200 | bin _time span=1d | stats sum(b) AS b by pool _time | eval GB = round(b/1024/1024/1024,3) | timechart span=1d max(GB) AS volume by pool fixedrange=false",\
\
$splitby$=="slave_name","`base_license_summary_search` pool=$pool_name$ | dedup slave, date_mday | eval _time=_time - 43200 | eval slave_guid=slave | bin _time span=1d | stats max(b) AS b by slave_guid, _time | join type=outer slave_guid [rest splunk_server=local /services/licenser/slaves | rename label AS slave_name title AS slave_guid | table slave_guid slave_name] | bin _time span=1d | stats max(b) AS b by slave_name _time | eval GB = round(b/1024/1024/1024,3) | timechart span=1d max(GB) AS volume by slave_name fixedrange=false",\
\
$splitby$=="st","`base_license_usage_search` | search pool=\"$pool_name$\" | bin _time span=1d | stats sum(b) AS b by st _time | eval GB = round(b/1024/1024/1024,3) | timechart span=1d sum(GB) AS volume by st fixedrange=false",\
\
$splitby$=="h","`base_license_usage_search` | search pool=\"$pool_name$\" | bin _time span=1d | stats sum(b) AS b by h _time | eval GB = round(b/1024/1024/1024,3) | timechart span=1d sum(GB) AS volume by h fixedrange=false",\
\
$splitby$=="s","`base_license_usage_search` | search pool=\"$pool_name$\" | bin _time span=1d | stats sum(b) AS b by s _time | eval GB = round(b/1024/1024/1024,3) | timechart span=1d sum(GB) AS volume by s fixedrange=false")

[pct_used_panel-generate_search_string(2)]
args = splitby, pool_name
definition = eval search_string = case(\
\
$splitby$=="none","`base_license_summary_search` pool=$pool_name$ | dedup slave, date_mday | eval _time=_time - 43200 | bin _time span=1d | stats sum(b) AS b max(stacksz) AS stacksz max(poolsz) AS poolsz by _time | eval maxsz = if(like(\"$pool_name$\",\"*\"),stacksz,poolsz) | eval \"% used\"=round(b/maxsz*100,2) | timechart span=1d max(\"% used\") AS \"% used\" fixedrange=false",\
\
$splitby$=="pool","`base_license_summary_search` pool=$pool_name$ | dedup slave, date_mday | eval _time=_time - 43200 | bin _time span=1d | stats sum(b) AS b max(stacksz) AS stacksz max(poolsz) AS poolsz by pool, _time | eval maxsz = if(like(\"$pool_name$\",\"*\"),stacksz,poolsz) | eval \"% used\"=round(b/maxsz*100,2) | timechart span=1d max(\"% used\") AS \"% used\" by pool fixedrange=false",\
\
$splitby$=="slave_name","`base_license_summary_search` pool=$pool_name$ | dedup slave, date_mday | eval _time=_time - 43200 | bin _time span=1d | stats sum(b) AS b max(stacksz) AS stacksz max(poolsz) AS poolsz by slave, _time | eval maxsz = if(like(\"$pool_name$\",\"*\"),stacksz,poolsz) | eval \"% used\"=round(b/maxsz*100,2) | eval slave_guid=slave | join type=outer slave_guid [rest splunk_server=local /services/licenser/slaves | rename label AS slave_name title AS slave_guid | table slave_guid slave_name] | timechart span=1d max(\"% used\") AS \"% used\" by slave_name fixedrange=false",\
\
$splitby$=="st","`base_license_usage_search` | search pool=\"$pool_name$\" | join _time pool type=outer [search index=_internal source=*license_usage.log type=\"RolloverSummary\" earliest=-30d@d | dedup slave, date_mday | eval _time=_time - 43200 | bin _time span=1d | stats max(stacksz) AS stacksz max(poolsz) AS poolsz by _time, pool] | eval maxsz = if(like(\"$pool_name$\",\"*\"),stacksz,poolsz) | stats sum(b) AS b max(maxsz) AS maxsz by st, _time | timechart span=1d max(eval(round(b/maxsz*100,2))) AS \"% used\" by st fixedrange=false",\
\
$splitby$=="h","`base_license_usage_search` | search pool=\"$pool_name$\" | join _time pool type=outer [search index=_internal source=*license_usage.log type=\"RolloverSummary\" earliest=-30d@d | dedup slave, date_mday | eval _time=_time - 43200 | bin _time span=1d | stats max(stacksz) AS stacksz max(poolsz) AS poolsz by _time, pool] | eval maxsz = if(like(\"$pool_name$\",\"*\"),stacksz,poolsz) | stats sum(b) AS b max(maxsz) AS maxsz by h, _time | timechart span=1d max(eval(round(b/maxsz*100,2))) AS \"% used\" by h fixedrange=false",\
\
$splitby$=="s","`base_license_usage_search` | search pool=\"$pool_name$\" | join _time pool type=outer [search index=_internal source=*license_usage.log type=\"RolloverSummary\" earliest=-30d@d | dedup slave, date_mday | eval _time=_time - 43200 | bin _time span=1d | stats max(stacksz) AS stacksz max(poolsz) AS poolsz by _time, pool] | eval maxsz = if(like(\"$pool_name$\",\"*\"),stacksz,poolsz) | stats sum(b) AS b max(maxsz) AS maxsz by s, _time | timechart span=1d max(eval(round(b/maxsz*100,2))) AS \"% used\" by s fixedrange=false")

[fb_bucket_transitions(2)]
args = host_arg, type
iseval = 1
definition = if(type=="kindle", "eventtype=bucket_kindle host=$host_arg$", if(type=="cool", "eventtype=bucket_cool host=$host_arg$", if(type=="chill", "eventtype=bucket_chill host=$host_arg$", if(type=="freeze", "eventtype=bucket_freeze host=$host_arg$", "(eventtype=bucket_kindle OR eventtype=bucket_cool OR eventtype=bucket_chill OR eventtype=bucket_freeze) host=$host_arg$"))))

[_fb_bucket_transitions_pretty(2)]
args = host_arg, type
iseval = 1
definition = if(type=="kindle", "eventtype=bucket_kindle host=$host_arg$ | `_fb_bucket_kindle_pp`", if(type=="cool", "eventtype=bucket_cool host=$host_arg$ | `_fb_bucket_cool_pp`", if(type=="chill", "eventtype=bucket_chill host=$host_arg$ | `_fb_bucket_chill_pp`", if(type=="freeze", "eventtype=bucket_freeze host=$host_arg$ | `_fb_bucket_freeze_pp`", "(eventtype=bucket_kindle OR eventtype=bucket_cool OR eventtype=bucket_chill OR eventtype=bucket_freeze)"))))

[_fb_bucket_transition]
definition = rename tag::eventtype AS mytag | eval Transition=case(mytag=="new_hotness", "New Hot", mytag=="hot_to_warm", "Hot to Warm", mytag=="warm_to_cold", "Warm to Cold", mytag=="bucket_freeze", "Freeze", 1==1, "Unknown")

[_fb_bucket_transition_reason]
#isnotnull(rolled), "Restart"
definition = eval Reason=case(isinit="true", "Restart", isinit="false", "Cluster Restart", count > maxHotBuckets, "Too Many Hot Buckets", diff > maxHotIdleSecs, "Bucket Idle Too Long", bucketSize > maxDataSize, "Bucket Hit Max Size:  " + maxDataSize, isnotnull(qbucket), "Quarantined event", transition="warm_to_cold", "Unknown", bucket_age > frozenTimePeriodInSecs, "Bucket Past Age Cutoff", transition="warm_to_cold", "Unknown", bucket_age > frozenTimePeriodInSecs, "Bucket Past Age Cutoff", currentSize > maxTotalDataSize, "Index Size Exceeded: " + maxTotalDataSize, 1==1, "New Event")  | eval Reason=if(isnotnull(timestamped), Reason + " at " + timestamped, Reason)

[_fb_bucket_transition_pp_renames]
definition = rename bucket AS "Bucket Name", idx AS Index, bucket_id AS "Bucket ID"

[_fb_bucket_transition_pp_table]
definition = table _time, Index, "Bucket ID", Transition, "Bucket Name", Reason

[fb_bucket_transition_pp]
definition = convert ctime(timestamped) | eval bucket_age=now - latest | `_fb_bucket_transition` | `_fb_bucket_transition_reason` | eval coldPath_expanded=bucket_parent | join type=left coldPath_expanded [ | rest /services/data/indexes | fields coldPath_expanded, title | rename title AS idx ] | eval homePath_expanded=bucket_parent | join type=left overwrite=f homePath_expanded [ | rest /services/data/indexes | fields homePath_expanded, title | rename title AS idx ] | `_fb_bucket_transition_pp_renames` | `_fb_bucket_transition_pp_table`


[rest_index_or_star(1)]
args = index_arg
iseval = 1
definition = if("$index_arg$" == "*", "rest /services/data/indexes", "rest /services/data/indexes/$index_arg$")

[splunk_server_or_star(1)]
args = host_arg
iseval = 1
definition = if("$host_arg$" == "*", "", "splunk_server=$host_arg$")

[by_host_or_server_or_star(2)]
args = host_arg, index_arg
iseval = 1
definition = if ("$host_arg$" == "*", if("$index_arg$" == "*", "by splunk_server, title", "by splunk_server"), if("$index_arg$" == "*", "by title", ""))

[bucketize_metrics]
definition = minspan=30s bins=200

[get_search_props]
definition = rex field=ARGS "_--id=(?<sid>.*?)_--"| eval role=if(like(sid,"%remote_%"),"search peer","search-head") | eval type=if(like(sid,"%scheduler_%"),"scheduled","ad-hoc") | eval mode=if(like(sid,"%rt_%"),"real-time","historical") | rex field=sid "remote_(?<dispatcher>[^_]*?)_" | rex field=ARGS "_--user=(?<user>.*?)_--"| eval dispatcher=if(isnull(dispatcher),"self",dispatcher)

[ps_sos_period]
definition = 5

[bucketize_ps_sos]
definition = bins=200 minspan=`ps_sos_period`s  

